{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "vital-ultimate",
   "metadata": {},
   "source": [
    "# Dummy\n",
    "\n",
    "## Lab: Survival Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-monkey",
   "metadata": {},
   "source": [
    "In this lab, we perform survival analyses on three separate data\n",
    "sets. In the first section we analyze the `BrainCancer`\n",
    "data .<br />\n",
    "Next, we examine the `Publication` data {islr}`from Section~\\\\ref{sec:pub};`. Finally, we explore explores\n",
    "a simulated call center data set.\n",
    "\n",
    "We begin by importing some of our libraries at this top\n",
    "level. This makes the code more readable, as scanning the first few\n",
    "lines of the notebook tell us what libraries are used in this\n",
    "notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-sudan",
   "metadata": {},
   "source": [
    "## Brain Cancer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-saying",
   "metadata": {},
   "source": [
    "We begin with the `BrainCancer` data set, which is part of the `ISLP`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "from ISLP import load_data\n",
    "BrainCancer = load_data('BrainCancer')\n",
    "BrainCancer.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-perception",
   "metadata": {},
   "source": [
    "The rows index the 88 patients, while the columns contain the 8 predictors.\n",
    "We first briefly examine the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print(BrainCancer['sex'].value_counts())\n",
    "print(BrainCancer['diagnosis'].value_counts())\n",
    "print(BrainCancer['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-telephone",
   "metadata": {},
   "source": [
    "Before beginning an analysis, it is important to know how the\n",
    "`status` variable has been coded.  Most software\n",
    "uses the convention that `status == 1` indicates an\n",
    "uncensored observation, and `status == 0` indicates a censored\n",
    "observation. But some scientists might use the opposite coding. For\n",
    "the `BrainCancer` data set 35 patients died before the end of\n",
    "the study. Similarly, it is important to understand the coding of any\n",
    "other qualitative variables: for instance, does `sex == 1` refer to\n",
    "males or females?\n",
    "\n",
    "To begin the analysis, we re-create a Kaplan-Meier survival curve shown in the book using the\n",
    "`KaplanMeierFitter` from the `lifelines` package.\n",
    "`tim` corresponds to $y_i$, the time to the $i$th event (either censoring or\n",
    "death). The first argument to `fit` are the event times with the\n",
    "second argument being the censoring variable with a 1 indicating an observed\n",
    "failure time. The `plot` method plots a curve with pointwise confidence\n",
    "intervals. By default, they produce 90% confidence intervals. This can be changed\n",
    "by setting the `alpha` argument to 1 minus the desired\n",
    "confidence level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "from lifelines import KaplanMeierFitter\n",
    "km = KaplanMeierFitter()\n",
    "km_brain = km.fit(BrainCancer['tim'],\n",
    "                  BrainCancer['status'])\n",
    "km_brain.plot() #SUPPRESSOUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-commissioner",
   "metadata": {},
   "source": [
    "Next we create Kaplan-Meier survival curves that are stratified by\n",
    "`sex`, in order to reproduce a second figure from the book.\n",
    "We will store the grouped data frames to use below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "by_sex = {}\n",
    "for sex, df in BrainCancer.groupby('sex'):\n",
    "    by_sex[sex] = df\n",
    "    km_sex = km.fit(df['tim'],\n",
    "                    df['status'])\n",
    "    km_sex.plot(label='Sex=%d' % sex) #SUPPRESSOUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-customer",
   "metadata": {},
   "source": [
    "As discussed in the book, we can perform a\n",
    "log-rank test to compare the survival of males to females. We use\n",
    "the `logrank_test` function from the `lifelines.statistics` module.\n",
    "The first two arguments are the event times, with the second\n",
    "denoting the corresponding (optional) censoring indicators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "from lifelines.statistics import logrank_test\n",
    "print(logrank_test(by_sex[0]['tim'],\n",
    "                   by_sex[1]['tim'],\n",
    "                   by_sex[0]['status'],\n",
    "                   by_sex[1]['status']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-astronomy",
   "metadata": {},
   "source": [
    "The resulting $p$-value is $0.23$, indicating no evidence of a\n",
    "difference in survival between the two sexes.\n",
    "\n",
    "Next, we fit  Cox proportional hazards models using the `CoxPHFitter` estimator\n",
    "from `lifelines`.\n",
    "To begin, we consider a model that uses `sex` as the only predictor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "from lifelines import CoxPHFitter\n",
    "coxph = CoxPHFitter()\n",
    "cox_fit = coxph.fit(BrainCancer,\n",
    "                    'tim',\n",
    "                    'status',\n",
    "                    formula='sex')\n",
    "cox_fit.summary[['coef', 'se(coef)', 'p']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-mambo",
   "metadata": {},
   "source": [
    "The first argument to `fit` should be a data frame containing\n",
    "at least the event time (the second argument `tim` in this case)\n",
    "as well as an optional censoring variable. The `formula` argument\n",
    "allows for convenient specification of a design matrix. With\n",
    "no `formula` argument, all columns besides the event time\n",
    "and censoring varible are used in the design matrix. Note that you\n",
    "may have issues with categorical variables without using the\n",
    "`formula` argument.\n",
    "It is possible to obtain the likelihood ratio test comparing this model to the one\n",
    "with only an intercept as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "cox_fit.log_likelihood_ratio_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-requirement",
   "metadata": {},
   "source": [
    "Regardless of which test we use, we see that there is no clear\n",
    "evidence for a difference in survival between males and females.  As\n",
    "we learned in this chapter, the score test from the Cox model is\n",
    "exactly equal to the log rank test statistic!\n",
    "\n",
    "Now we fit a  model that makes use of additional predictors. We first note\n",
    "that one of our `diagnosis` values is missing hence\n",
    "we drop that observation before continuing. Also\n",
    "note that not supplying a formula uses all columns in the regression.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "cleaned = BrainCancer.dropna()\n",
    "formula = 'diagnosis + sex + loc + ki + gtv + stereo'\n",
    "fit_all = coxph.fit(cleaned, 'tim', 'status', formula=formula)\n",
    "fit_all.summary[['coef', 'se(coef)', 'p']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-spread",
   "metadata": {},
   "source": [
    "The `diagnosis` variable has been coded so that the baseline\n",
    "corresponds to meningioma, and a value of 2 corresponds to HG\n",
    "glioma. The results indicate that the risk associated with HG glioma\n",
    "is more than eight times (i.e. $e^{2.15}=8.62$) the risk associated\n",
    "with meningioma. In other words, after adjusting for the other\n",
    "predictors, patients with HG glioma have much worse survival compared\n",
    "to those with meningioma.  In addition, larger values of the Karnofsky\n",
    "index, `ki`, are associated with lower risk, i.e. longer survival.\n",
    "\n",
    "Finally, we plot estimated survival curves for each diagnosis category,\n",
    "adjusting for the other predictors.  To make these plots, we set the\n",
    "values of the other predictors equal to the mean.  To avoid clutter in\n",
    "the plots, we do not display confidence intervals.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "fit_all.plot_partial_effects_on_outcome('diagnosis',\n",
    "                                        values=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-handbook",
   "metadata": {},
   "source": [
    "## Publication Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-appraisal",
   "metadata": {},
   "source": [
    "The `Publication` data   can be\n",
    "found in the `ISLR2` library.\n",
    "We begin by plotting the Kaplan-Meier curves\n",
    "stratified on the `posres` variable, which records whether the\n",
    "study had a positive or negative result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "Publication = load_data('Publication')\n",
    "by_result = {}\n",
    "for result, df in Publication.groupby('posres'):\n",
    "    by_result[result] = df\n",
    "    km_result = km.fit(df['tim'], df['status'])\n",
    "    km_result.plot(label='Result=%d' % result) #SUPPRESSOUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-isolation",
   "metadata": {},
   "source": [
    "As discussed previously, the $p$-values from fitting Cox’s\n",
    "proportional hazards model to the `posres` variable are quite\n",
    "large, providing no evidence of a difference in time-to-publication\n",
    "between studies with positive versus negative results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "posres_fit = coxph.fit(Publication,\n",
    "                       'tim',\n",
    "                       'status',\n",
    "                       formula='posres')\n",
    "posres_fit.summary[['coef', 'se(coef)', 'p']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-fight",
   "metadata": {},
   "source": [
    "As expected, the log-rank test provides an identical conclusion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print(logrank_test(by_result[0]['tim'],\n",
    "                   by_result[1]['tim'],\n",
    "                   by_result[0]['status'],\n",
    "                   by_result[1]['status']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-guatemala",
   "metadata": {},
   "source": [
    "However, the results change dramatically when we include other\n",
    "predictors in the model. Here we have excluded the funding mechanism\n",
    "variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "formula = ('posres + multi + clinend ' +\n",
    "          '+ sampsize + budget + impact')\n",
    "coxph.fit(Publication,\n",
    "          'tim',\n",
    "   'status',\n",
    "   formula=formula).summary[['coef', 'se(coef)', 'p']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-passenger",
   "metadata": {},
   "source": [
    "We see that there are a number of statistically significant variables,\n",
    "including whether the trial focused on a clinical endpoint, the impact\n",
    "of the study, and whether the study had positive or negative results.\n",
    "\n",
    "## Call Center Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-organic",
   "metadata": {},
   "source": [
    "In this section, we will simulate survival data using the relationship\n",
    "between cumulative hazard and\n",
    "the survival function explored in an exercise.\n",
    "Our simulated data will represent the observed\n",
    "wait times (in seconds) for 2,000 customers who have phoned a call\n",
    "center.  In this context, censoring occurs if a customer hangs up\n",
    "before his or her call is answered.\n",
    "\n",
    "There are three covariates: `Operators` (the number of call\n",
    "center operators available at the time of the call, which can range\n",
    "from $5$ to $15$), `Center` (either A, B, or C), and\n",
    "`Time` of day (Morning, Afternoon, or Evening). We generate data\n",
    "for these covariates so that all possibilities are equally likely: for\n",
    "instance, morning, afternoon and evening calls are equally likely, and\n",
    "any number of operators from $5$ to $15$ is equally likely. We use the\n",
    "`dmatrix` function from the `patsy` library introduced\n",
    "in Chapter 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "from patsy import dmatrix\n",
    "np.random.seed(10)\n",
    "N = 2000\n",
    "Operators = np.random.choice(np.arange(5, 16),\n",
    "                             N,\n",
    "                             replace=True)\n",
    "Center = np.random.choice(['A', 'B', 'C'], \n",
    "                          N,\n",
    "                          replace=True)\n",
    "Time = np.random.choice(['Morn.', 'After.', 'Even.'], \n",
    "                        N,\n",
    "                        replace=True)\n",
    "D = pd.DataFrame({'Operators': Operators,\n",
    "                  'Center': Center,\n",
    "                  'Time': Time})\t\t       \n",
    "X = dmatrix(\"Operators + Center + Time\",\n",
    "            D,\n",
    "            return_type='dataframe')\n",
    "X = X.drop(['Intercept'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-wrong",
   "metadata": {},
   "source": [
    "It is worthwhile to take a peek at the design matrix `X`, so\n",
    "that we can be sure that we understand how the variables have been\n",
    "coded.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-breast",
   "metadata": {},
   "source": [
    "Next,  we specify the coefficients and the hazard function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "true_beta = np.array([-0.3, 0, 0.2, -0.2, 0.04])\n",
    "true_linpred = X.dot(true_beta)\n",
    "hazard = lambda t: 1e-5 * t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-discount",
   "metadata": {},
   "source": [
    "To simulate the data we use a standard trick to simulate\n",
    "random variables whose survival function is known, particularly\n",
    "its inverse: if $S(t;x)$ is the survival function with\n",
    "covariates $x$ then a random time satisfies\n",
    "\n",
    "$$\n",
    "S(T;x) \\sim \\text{Unif}(0,1)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-cycling",
   "metadata": {},
   "source": [
    "Using the relationship\n",
    "\n",
    "$$\n",
    "S(t;x) = \\exp(-H(t;x))=\\exp(-H_0(t)\\exp(x^T\\beta))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-childhood",
   "metadata": {},
   "source": [
    "we see that\n",
    "$T$ at covariates $x$ can be simulated using the inverse\n",
    "of the baseline cumulative hazard at that $x$. With $U \\sim \\text{Unif}(0,1)$\n",
    "\n",
    "$$\n",
    "T = H^{-1}_0(-\\log(U) \\exp(-x^T\\beta))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-profile",
   "metadata": {},
   "source": [
    "This simple function allows us to generate data\n",
    "with a known inverse cumulative hazard baseline function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "def sim_time(linpred, inv_cum_hazard, cutoff=1000):\n",
    "    while True:\n",
    "        U = np.random.sample()\n",
    "        T = inv_cum_hazard(-np.log(U) /\n",
    "                           np.exp(linpred))\n",
    "        if T < cutoff:\n",
    "            return T\n",
    "\n",
    "cum_hazard = lambda t: 1e-5 * t**2 / 2\n",
    "inv_cum_hazard = lambda v: np.sqrt(2 * v / 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-comparative",
   "metadata": {},
   "source": [
    "Here, we have set the coefficient associated with `Operators` to\n",
    "equal $0.04$; in other words, each additional operator leads to a\n",
    "$e^{0.04}=1.041$-fold increase in the “risk” that the call will be\n",
    "answered, given the `Center` and `Time` covariates. This\n",
    "makes sense: the greater the number of operators at hand, the shorter\n",
    "the wait time! The coefficient associated with `Center == B` is\n",
    "$-0.3$, and `Center == A` is treated as the baseline. This means\n",
    "that the risk of a call being answered at Center B is 0.74 times the\n",
    "risk that it will be answered at Center A; in other words, the wait\n",
    "times are a bit longer at Center B.\n",
    "\n",
    "We are now ready to generate data under the Cox proportional hazards\n",
    "model. We’ll truncate the maximum time to 1000 seconds to keep\n",
    "simulated wait times reasonable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "D['y'] = np.array([sim_time(l, inv_cum_hazard)\n",
    "            for l in true_linpred])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-patrol",
   "metadata": {},
   "source": [
    "We know simulate our censoring variable, for which we assume\n",
    "90% of calls were answered (`failed==1`) before the\n",
    "customer hungup (`failed==0`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-cyprus",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "D['failed'] = np.random.choice([1, 0],\n",
    "                                N,\n",
    "                                p=[0.9, 0.1])\n",
    "D[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-subsection",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "D['failed'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-romania",
   "metadata": {},
   "source": [
    "We now plot  Kaplan-Meier survival curves. First, we stratify by `Center`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "by_center = {}\n",
    "for center, df in D.groupby('Center'):\n",
    "    by_center[center] = df\n",
    "    km_center = km.fit(df['y'], df['failed'])\n",
    "    km_center.plot(label='Center=%s' % center)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Probability of Still Being on Hold\") #SUPPRESSOUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-profit",
   "metadata": {},
   "source": [
    "Next, we stratify by `Time`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "by_time = {}\n",
    "for time, df in D.groupby('Time'):\n",
    "    by_time[time] = df\n",
    "    km_time = km.fit(df['y'], df['failed'])\n",
    "    km_time.plot(label='Time=%s' % time)\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"Probability of Still Being on Hold\")  #SUPPRESSOUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-voice",
   "metadata": {},
   "source": [
    "It seems that calls at Call Center B take longer to be answered than\n",
    "calls at Centers A and C. Similarly, it appears that wait times are\n",
    "longest in the morning and shortest in the evening hours. We can use a\n",
    "log-rank test to determine whether these differences are statistically\n",
    "significant using `multivariate_logrank_test`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "print(multivariate_logrank_test(D['y'],\n",
    "                                D['Center'],\n",
    "                                D['failed']))\n",
    "print(multivariate_logrank_test(D['y'],\n",
    "                                D['Time'],\n",
    "                                D['failed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-vietnam",
   "metadata": {},
   "source": [
    "As in the case of a categorical variable with 2 outcomes, these\n",
    "results are similar to the likelihood ratio test\n",
    "from the Cox proportional hazards model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print(coxph.fit(D, 'y', 'failed', formula='Center').log_likelihood_ratio_test())\n",
    "print(coxph.fit(D, 'y', 'failed', formula='Time').log_likelihood_ratio_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-conviction",
   "metadata": {},
   "source": [
    "We find that differences between centers are highly significant, as\n",
    "are differences between times of day.\n",
    "\n",
    "Finally, we fit Cox’s proportional hazards model to the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "formula = 'Operators + Time + Center'\n",
    "fit_queuing = coxph.fit(D,\n",
    "                        'y',\n",
    "                        'failed',\n",
    "                        formula=formula)\n",
    "fit_queuing.summary[['coef', 'se(coef)', 'p']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-projector",
   "metadata": {},
   "source": [
    "The $p$-values for `Center == B` and `Time == Even.`\n",
    "are very small. It is also clear that the\n",
    "hazard — that is, the instantaneous risk that a call will be\n",
    "answered — increases with the number of operators. Since we\n",
    "generated the data ourselves, we know that the true coefficients for\n",
    "`Center == B`, `Center == C`,\n",
    "`Time == Even.`, `Time == Morn.` and `Operators`  are $-0.3$,\n",
    "$0$, $0.2$, and $-0.2$, $0.04$, respectively. The coefficient estimates\n",
    "resulting from the Cox model are fairly accurate."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "formats": "ipynb,Rmd",
   "notebook_metadata_filter": "all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
